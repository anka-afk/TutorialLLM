# 第8节 做一个听话的AI

{% hint style="success" %}
**本节导读**

人们发明AI，是希望AI可以成为人类的助手。它不仅需要学会说话，更重要的是理解人的意图，听从我们的要求。读完本节，你将会了解：

* 对话AI的原理
* 如何教会AI根据题目写诗
{% endhint %}

## 文本补全 vs 对话

在贯穿全书的案例中，读者或许能够发现，训练数据的组织方式决定了模型的实际行为。之所以训练出的模型会一首接一首地写诗，是因为我们的训练数据就是这样设计的。在我们的数据集中，所有诗首尾相连串在一起，模型学习这些文本中的表述方式，自然也就学会了不停写诗。我们曾在[第2节](di-2-jie-cong-yi-ge-shi-ji-an-li-ru-shou.md)中提及，这种行为被称为文本补全（completion）。

对于OpenAI的GPT系列模型来说，预训练的结果也是不停地输出文字。假如你提出一个问题，模型大概率不会回答你这个问题，而是尝试模仿你提问的方式无休止地提出其它问题。当然，你可能说，ChatGPT可不是这样。的确，那是因为ChatGPT并不属于预训练模型，而是经过了指令微调（Instruction Fine-tune）后的结果。

现在，我们有了一个只会文本补全的预训练模型，如何才能把它变成能回答问题乃至对话的聊天模型呢？

其实，问答或聊天本质上也是文本，只不过每段文本被定义为不同的类别。对于ChatGPT来说，文本共有三种类别，分别是system（系统）、user（用户）和assistant（助手）。如果你用过OpenAI Chat API，你一定明白它们各自的含义。简单来说，system用来设定AI在会话中的角色。比如，我们设置system文本为“你是一个优秀的心理咨询师”，模型后续的回复就会以心理咨询师的角色开展。user文本是用户给模型的实际输入，比如“我最近很郁闷，能告诉我该怎么办吗？”输入system文本和user文本，模型就会输出assistant类别的文本，比如“我理解你现在的感受，感觉郁闷时常常会让人有些迷茫。你能告诉我是什么让你感到郁闷吗？”

我们将输入的system文本和user文本称为prompt（提示词），意为用这些内容提示大模型使其生成所需的结果。

作为用户，我们已经习惯了在聊天窗口中与ChatGPT聊天。但实际上，网页背后的数据以system prompt、user prompt、assistant response的格式存在。用户输入后，网站把system prompt和user prompt输入模型，模型运行完毕后提取出assistant response返回到用户界面。

<figure><img src=".gitbook/assets/chatgpt-example.jpg" alt="" width="375"><figcaption><p>图13 向ChatGPT倾诉</p></figcaption></figure>

{% hint style="info" %}
图13展示了一个常见的ChatGPT使用场景。大部分商用模型并不支持自定义system prompt，它们会内置一个默认的system prompt，类似于

> You are ChatGPT, a large language model trained by OpenAI.\
> Knowledge cutoff: 2023-10\
> Current date: 2024-11-30

而用户只能输入user prompt，ChatGPT会返回assistant response。如果购买了OpenAI的API，则可以自定义system prompt，达到更个性化的控制。
{% endhint %}

OpenAI是如何做到这种效果的呢？正如开头所说，想要怎样的效果，就要用怎样的数据训练。OpenAI的数据团队会收集大量对话数据，整理成system、user、assistant的格式，然后以同样的方式继续训练模型。此时的训练就叫做指令微调。对于刚刚举的例子，数据团队整理后的文本大概长这样：

> \[system]你是一个优秀的心理咨询师\[user]我最近很郁闷，能告诉我该怎么办吗？\[assistant]我理解你现在的感受，感觉郁闷常常会让人有些迷茫。你能告诉我是什么让你感到郁闷吗？

可以看到，文本被插入了用方括号包裹的关键词。只要每条数据都用这几个关键词标注，模型在训练过程中就会慢慢明白这几个关键词的含义，从而将自己调整为一个对话模型。训练完毕后，只要输入包含system和user的前半部分，模型就可以输出assistant的后半部分，从而达到对话的效果。更重要的是，这类文本有明确结尾。无论system、user还是assistant，为了符合对话的主题，它们的长度必然是有限的。模型可以从中学习到如何生成合适长度的回答，而不是无休止地扩展话题。

## 指令微调

现在，回到我们的写诗场景。考虑可行性，我们选择一个容易学会的对话模式——根据题目写诗。这样的训练数据很多，我们可以把每首诗都整理成如下的格式：

> \<INS>請用以下題目寫一首詩\<INP>春夜喜雨\<RES>好雨知時節，當春乃發生。\n隨風潛入夜，潤物細無聲。\n野徑雲俱黑，江船火獨明。\n曉看紅濕處，花重錦官城。

模型反复学习这种格式的文本，就会明白INS（instruction）、INP（input）、RES（response）分别代表指令、题目以及正文。当然，这里的关键字也是可以随便取的，只要训练和使用时保持一致即可。在我们的例子中，指令部分是固定的，我们只要求模型做这一项任务。如果是OpenAI等商用模型，他们会提供非常丰富的指令以训练模型能够从事各种任务。

指令微调的训练通常短于预训练。因为预训练阶段模型已经学会了如何说话，微调只是告诉它需要遵循的格式。因而只需要训练一个增量，不必重头开始。我们以[第7节](di-7-jie-cong-zhi-zhang-dao-tian-cai.md)预训练后的模型为基础，按照刚刚介绍的数据格式进行微调，可以看到如下效果。

```
Epoch 0, step 0, train loss 0.0000, evaluate loss 8.5504
Generate a complete poem for title 春夜喜雨:
文請，曾說春來淚故花楊柳枝。

山中峰寺仙二首 二
高齋吟商賈居仙，欲嘯花開開却閉絲。
硯通四也應不見，却向宮江盡北山。
一字多堪杖不顧，紫芝多不見青山。
定開照鏡匳梅雨，上倚升階遶樹陰。
來此醉君

<Omit many iterations here...>

Epoch 4, step 800, train loss 3.2089, evaluate loss 3.3451
Generate a complete poem for title 春夜喜雨:
山村春色引，雨水曉光斜。
更問月中鏡，空啼千萬傳。
隱隱閑臥竹，神盤暗自風。
殘春望江島，不見磬聲王。
```

同样是每训练一段时间让模型试着输出一首诗。可以看到，在step为0时，模型还未开始微调，输出的文字虽然是诗句，但不是一首完整的诗。到第4轮的800步，输出变得很整洁。而且可以隐约感觉到，诗句的内容已经接近题目“春夜喜雨”的含义。模型像一个真正的对话AI一样，给出了有意义的答复。

至此，模型已经表现得有模有样，但别急，精彩的环节才刚刚开始。大模型在2023年爆发，最厉害的既不是预训练，也不是指令微调，而是下一节将要介绍的与人类偏好对齐。
