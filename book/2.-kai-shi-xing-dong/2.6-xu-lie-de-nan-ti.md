# 2.6 序列的难题

新的问题正是我们在2.4节提到的，输入文本长短不一。

输入数据的语义化并没有改善这个问题，反而让它变得更复杂了。原本，我们面对的困难是，输入字数在1\~255之间变化。现在可好，输入变成了1\*1024\~255\*1024，范围扩大了许多。如果仿照2.4节的模式设计模型结构的话，对于字数最多的情况，模型就会长下面这样。

<figure><img src="../.gitbook/assets/flatten_full_connection.png" alt=""><figcaption><p>图2.2 所有字的1024维向量首尾相连作为神经网络的输入</p></figcaption></figure>

其中，输入层把所有文字的1024维向量全部排成一排；中间层数量可以任意设置，但一般不会和前后层差距过大；输出层输出1024个数。这里的实际输出正好和我们准备的期望输出维数一致，因而可以用来评估模型距离目标的差距，并在训练过程中减小这个差距。

理论上这样做可行，但我们其实很容易看到其中潜在的问题。

一方面，这种做法似乎泯灭了每个字的独立性，把它们全部混在一起了。另一方面，输入层和中间层的连接变得密密麻麻。连线的数量等于输入神经元的数量乘以中间层神经元的数量，这会是一个相当大的数字。图中并没有给出中间层神经元具体是多少个，但按照经验，相邻层的神经元数量不宜相差过大，所以整个神经网络的计算量将会放大约1024²倍。

有没有办法改善这两个问题呢？

或许可以把每个字的1024维向量明确分开，以组为单位进行处理，像下面这个样子。

<figure><img src="../.gitbook/assets/grouped_full_connection.png" alt=""><figcaption><p>图2.3 神经网络的每一层都以组的单位接收或处理数据</p></figcaption></figure>

的确，连线变得非常稀疏，好像又回到了最初使用ID输入的模式，只不过每个输入现在不是一个ID，而是一个1024维的向量。

虽然看起来很清爽，但实际上，这个图并没有说清楚数据是如何在神经元之间传递的。在图2.2中，每条箭头明确地代表一个数，中间层神经元接收到几个箭头，它代表的函数就有几个自变量。而图2.3中，中间层的一组神经元接收来自输入的255组神经元的数据，但具体的每个神经元接收到哪些数据，图中并没有说明。也就是说，图中的连接定义了一种开放的模型结构，它只规定一组神经元连接到另一组神经元，但具体组的内部如何处理这些数据，可以有不同的实现方式。

至于怎样实现最好，下节就来揭晓答案。
