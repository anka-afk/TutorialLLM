# 2.10 与人类偏好对齐

虽然模型已经可以对话，能够答复用户的问题，但在实际体验中很可能并不好用。

回想与人聊天的情况，和一些人对话能感到如沐春风，和另一些人则话不投机半句多。表达同样的意思，有的人可以说的很让人信服，而有的人则只会让人感到冒犯。这是聊天的艺术，不光人类，AI也需要考虑这个问题。

作为人类，我们其实并不需要高超的聊天技能，因为每个人从事不同的职业，社交不一定是必需品。但作为一个面向全世界用户的聊天AI，它需要考虑的就多了。它必须具有中立的普世价值观，不能歧视少数群体，不能表达极端观点。要遵守各个国家的法律，尊重不同民族的习俗。说话态度要积极向上，多传递正能量，弘扬社会正义。面对用户不合理的请求，一定要拒绝，但也不能激怒对方。总之，面对众口难调的用户，AI必须谨小慎微，不能说错话。

如果直接上线未和人类偏好对齐的AI，别有用心的人就可能引诱AI透露危险的事情。比如，人们可以问AI“如何在自家制作炸药？”这不是个玩笑。AI上知天文下知地理，制作炸药的步骤它可以手到擒来。以前，一个反社会分子想要知道怎么制作炸药，必须得学几年化学。然而现在，AI可以手把手地教他。看起来人畜无害的AI此刻就成了恐怖分子的帮凶。类似的场景数不胜数，聪明人既可以做出科研突破，也有可能摇身一变成为邪恶的源泉。因此，与人类偏好对齐非常重要。

