# 2.4 高维语义空间

先来尝试解决输入无意义的问题。

回想我们自己，当读到一个字的时候，几乎瞬间就能明白它的含义。整个过程甚至是下意识的，仿佛大脑中隐含着一个字典，一看到这个字就能立即跳转到其解释。但此字典非我们前面提到的字典。在[2.2节](2.2-cong-wen-ben-dao-shu-zi.md)，我们只是把字转换到了ID，而大脑则会更进一步，把字转换成它的含义。我们尚不知道这种含义如何在大脑中存储和表示，但我们可以肯定地说，它一定不只是一个ID。

从数学的角度上看，任何事物都可以用数字表示。ID可以用数字表示，事物的含义其实也可以用数字表示。不过，当我们用数字表示含义的时候，它必须具有内在价值，或者说存在物理解释。比如，用摄氏度表示温度，每个数字都与具体的物理世界相关联，0℃正好对应着冰的熔点。这种物理解释将数字本身的性质与物理现象统一起来，越小的数代表越低的温度，而且温度变化和数字变化的规律是一致的，也就是说，数字加减乘除的结果仍然可以解释，于是对温度的研究就可以转化为数学运算。

回到文字上，文字在大脑中的理解其实也存在物理解释，它可能是神经元突触间特定的激活模式，只是我们不十分了解。既然如此，不如由我们自己来创造一个物理解释。

首先，文字的含义本质上是信息。信息是一个很广的概念，任何事物，实在的或抽象的，都可以认为是信息。信息产生的目的是方便人们沟通，当我说“我很渴”的时候，你就能想到我需要喝水。“渴”和“水”这两个字虽然一个抽象一个具体，指向不同的事物，但它们之间有着紧密的联系。本质上，这种关联衡量了事物之间的相似性。而整个世界恰恰是由相似性联结起来的，你可以试着想象，如果任何事物都和其它事情毫无关联，我们该如何理解这个世界。

那么，以相似性为基础，我们应该让相似的字用相似的数来表示。就像温度一样，相近的温度对应的数值应该更接近。但对文字来说这个要求很难满足，因为字和字之间的相似性不是单调排布的。“渴”和“水”含义相近，这种相似体现在动物的生理行为层面。同时，我也可以说“水”和“油”相似，因为它们都是液体。但由此并不能说明“渴”和“油”相似，因为渴了并不应该喝油。于是，这种相似性的排序会成为巨大的难题。我们不可能在一条数轴上安排好所有字的合适位置，换句话说，我们不能用一个数来代表一个字。

谈到此处，读者或许已经明白了我的意图——我们应该用多个数来表示一个字。如果用两个数表示一个字，就意味着把所有字安排在二维平面上。如果用三个数，就意味着把所有字安排在三维空间中。然而，即使是三维空间也仍然不够用，它不足以区分文字内在的微妙含义。因为本质上，几维空间就意味着我们需要在几个层面上把所有字排好序。可想而知，任何一个字恐怕都包含了不止三重含义，所以三维是不够的。

继续升维，就进入了所谓的高维空间。我们不如一步到位，选一个很高的维度，以免不够用，假设是1024维。用1024个数来表示一个字，每个数代表某个特定层面的微妙含义，我估计是够了。

不过，我们如何定义每个维度的含义呢？很显然，我们定义不了，根本不知道该如何找出1024种微妙的解释。但没关系，别忘了我们有神经网络。上一节，我们事先定义好输入的维度和每个维度的解释，然后交给神经网络处理。实际上，我们也可以不定义每个维度的解释，只是告诉神经网络输入维度是1024，让它通过数据自己学习每个维度的意义。

但没有解释的话，输入的这1024个值如何确定呢？

既然我们已经决定让模型自己学习每个维度的解释，那索性每个维度的值也交给模型学习就好了。一开始，我们只需要设置1024个随机值，模型在训练的过程中自然会明白如何合理地拆分字的含义，将其融入这1024个维度中。

为了更方便理解，我们把[2.2节](2.2-cong-wen-ben-dao-shu-zi.md)的输入数据拿过来试试。首先，输入输出的文本长这样

> **Input**: 白日依山盡，黃河入海
>
> **Output**: 流

紧接着，它们被转换为ID。

> **Input**: \[4403, 2704, 345, 1642, 4450, 8347, 8252, 3407, 536, 3503]
>
> **Outpu**: 3486

然后，就来到了本节介绍的操作，把每个ID转换为一个1024维的向量。大概长这样

> **Input**: \[
>
> \[0.0248, 1.0818, 1.0172, -2.5224, ...(省略1020个数)],
>
> \[0.1242, -0.2566, -0.0985, -0.0295, ...(省略1020个数)],
>
> ...(省略8行)
>
> ]
>
> **Output**: \[-0.4783, 0.4503, -1.5498, -1.3663, ...(省略1020个数)]

可以发现，每个数都在0附近不大的范围内。事实上，这些随机数是以0为均值、1为方差采样得到的。这样做可以保证输入局限于一个合理的区间，不至于太大或太小。

不过，读者可能仍然会感到迷惑，输入都是随机数，输出也是随机数，那模型到底在学什么呢？

如果想到了这个问题，说明你关注到了重点。这里的随机1024维向量并不是在每次输入时生成的，而是在创建字典时生成的。也就是说，每个向量唯一对应于字典中的一个ID，字典被扩展成了一个巨大的表格。

| ID   | Embedding                                  |
| ---- | ------------------------------------------ |
| 0    | \[0.1236, -2.1807, 0.3700, 0.4144, ...]    |
| 1    | \[-1.2415, -0.1413, -0.5798, -0.3694, ...] |
| 2    | \[-0.3648, -0.9364, -0.8821, 0.2193, ...]  |
| ...  | ...                                        |
| 8547 | \[0.5925, 0.7216, -0.3418, 0.5955, ...]    |

对于任何输入文本，文本中的每个字都查表得到其对应的向量。虽然训练的时候模型会调整向量的值，但特定的向量始终和特定的字绑定。模型虽然表面上在学习向量之间的关系，但实际上学到的是向量绑定的字之间的关联。

{% hint style="info" %}
这种高维且内化了特定语义的向量通常被称作embedding，原意是“嵌入”，引申为将含义内嵌在向量空间中。
{% endhint %}

现在，输入终于变得有意义了，但另一个问题接踵而至。
