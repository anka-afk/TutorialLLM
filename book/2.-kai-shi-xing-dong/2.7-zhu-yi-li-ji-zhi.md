# 2.7 注意力机制

图2.3的连线其实有更为直观的解释。由于每组向量对应于一个字，我们可以认为它构建了字与字之间的连接关系。细心的同学可能发现，虽然中间层每组向量的元素个数可以与输入不同，但向量的组数却仍然是255个。图中可以看到，每个输入向量都发出了一条水平箭头指向右侧的中间层向量。这其实是经过精心设计的。

理论上，中间层的组数也可以任意设置，就像图2.2中的连接一样，不用考虑中间层具体有多少个神经元。但让它和输入层数量一致有明显的好处。一方面，从语义上我们更容易区分每个中间层向量到底与哪个字对应；另一方面，我们可以增加层数，在中间层和输出层之间再插入若干个中间层，而且每一层的每个向量都可以对应于特定的字。

当向量与字对应之后，我们就对整个神经网络在做的事情有了一个宏观的了解。比如，我们可以认为，图2.3中间层的第一组神经元尝试从输入的255个字中提取信息，以加深自己对第一个字的理解。换句话说，第一个字在1024维空间中的高维表示从输入向量变成了中间层的输出向量，而且综合了其它字的信息。可能你暂时想不明白这个变化意味着什么，让我们来看个例子。

假设输入的是这么一句话：“只要你向着阳光走，影子就会躲在后面”。这句话里面，“光”预示着光明的未来，是一种积极的意象。但如果换成这句：“我炒股把家底都输光了”。这里的“光”则表示空空如也，暗示着悲惨的结局。多义字在中文并不少见，这也是为什么2.5节强调了我们要在高维空间中表示字的含义。然而，虽然输入层的“光”需要包括它所蕴含的各种含义，中间层则不一定。在看过了整句话中的其它字后，作为人类，我们很容易明白，“光”在当前这句话中应取其积极含义。于是，中间层的“光”可以只保留有关的含义而丢弃无关的含义，向量在1024维空间中从原始位置移动到另一个更接近其真实用意的位置。这便是我们希望神经网络做的事情。

{% hint style="info" %}
我们从神经网络的结构推测其内部的工作机制，虽然不一定对，但结构与功能通常是紧密相关的。正因为我们希望它以某种方式处理数据，我们才把网络设计成特定的样子。本文有时以目标出发引导大家想出合理的方案，但有时我会直接给出合理的方案，然后解释为什么这样设计。希望读者可以跟随文中的思路，必要时停下来思考一下再往后读。
{% endhint %}

如果进一步细化这件事，我们会发现里面包含了两个关键操作。

第一是把其它字与当前字关联起来，从而缩窄当前字的含义范围。这一步往往要求我们注意某些真正重要的字，而不必在意其它无关紧要的字。比如，对于“只要你向着阳光走，影子就会躲在后面”这句话，对“光”的含义影响最大的字显然是“阳”和“影”。因为假设盖住“光”字把这句话变成一个完形填空，看到“阳”和“影”大概就能明白需要填什么。这种寻找重点字的过程，被称为“注意力机制”。注意力机制是大模型基础架构中最有含金量的部分，我们终于慢慢进入了AI的核心。

第二是参考注意到的其它字，把当前字的1024维向量移动到合适的位置，即改变其内涵。

其实第二步操作比较好实现，向量在高维空间的移动本质上就是一个线性变换。如果想要把一个1024维向量变成另一个1024维向量，只需要乘上一个1024×1024的矩阵。事实上，我们前面所介绍的神经网络就是在做这件事，下图展示了神经网络等价的矩阵运算。

<figure><img src="../.gitbook/assets/transform_embedding.png" alt=""><figcaption><p>图2.4 神经网络将输入向量变换到输出向量，等价于左乘一个矩阵</p></figcaption></figure>

你可以将矩阵中的元素对应到神经网络中的箭头。每条箭头包含了一个权重，用于对输入加权求和。矩阵乘法本质上也在做同样的事。在神经网络中，神经元的权重（或者说权重矩阵）就是模型的参数，训练模型其实就是调整这些权重。

{% hint style="info" %}
需要注意的是，前文曾经提到过，人工神经元本质上是一个非线性函数，但没有提及具体实现。事实上，非线性函数往往是两个函数的叠加，先经由上图的线性变换，再施加一个非线性激活函数，比如ReLU。非线性激活函数的作用是给神经元添加一点点非线性，因为线性函数的叠加永远是线性，只有加入非线性，神经网络才能拟合更复杂的现象。本文的图解为了简单清晰，避免引入过多细节，与当前主题无关的非线性激活函数并未特地标出，请读者谅解。
{% endhint %}

解决了第二步，我们再回到第一步，思索一下如何实现字与字之间的注意力机制。

先重新概括一下我们的问题。假设我们有255个字组成的输入数据，每个字用1024维向量表示。我们希望通过某种类似于注意力的机制，让每个字的1024维向量融入其它字的信息，然后以新的255个1024维向量作为输入，进入上面讨论过的第二步，也就是图2.4中的操作。

这个问题其实仍然有些抽象，我们可以具体逐字分析一下具体的任务。

首先，把其它字的信息融入当前字的向量是什么意思？说白了，信息只隐含在向量里，所以我们应该是把其它字的向量融合到当前字的向量里面。但是怎么融合？最简单的方式仍然是加权求和。把其它字的向量乘上某个权重，然后叠加到当前字的向量中。

这一操作也略有迷惑性，你或许会认为，把其他字叠加到当前字难道不会混淆信息吗？就好像把255个字写在一个格子里，谁还能看得出来这是什么字。但不要忽略高维空间的性质，一个字蕴藏的含义可能压根没有1024种，在特定的上下文中，含义则进一步收缩，1024维向量其实包含了许多冗余，因此不必担心信息放不下的问题。

然而，注意力体现在哪里呢？显然它只能体现在权重上。如果恰好让重要的字权重高，不重要的字权重低，那的确是个好方案。考虑到刚刚介绍的知识，是不是可以用一个255×255的权重矩阵来操作向量呢？毕竟，模型训练的过程会自动学习到如何给每个字分配权重。

但很遗憾，这里会重新遇到前文讨论过的输入长短不一的问题。如果我们训练的时候限制最大输入长度是255，使用的权重矩阵大小就要锁死为255×255。那么一旦我们想要用于更长的输入文本，模型就得重新训练。甚至用于更短文本的时候，模型都可能表现不佳。因为输入长度被作为模型参数的一部分，严重限制了泛化能力。

怎样才能找到一个与输入长度无关的权重，而且能调控注意力呢？

我想到一个线索。大家或许在数学课上学到过一个公式叫余弦相似度，用来衡量两个向量之间的相似程度。有没有发现，我们所追求的注意力，是不是可以看作某种意义上的相似度呢？这样的话，如果直接计算向量和向量之间的余弦相似度，然后用这个值作为权重，把其它向量叠加到当前向量中，是不是就摆脱了与长度相关的那个权重矩阵？我们用下图详细说明这个过程。

<figure><img src="../.gitbook/assets/naive_attention.png" alt=""><figcaption></figcaption></figure>



为什么需要两步，第一步不是包含了第二步吗？第二步只在向量内部做变换，而且参数是共用的。但第一步在向量之间做变换。
