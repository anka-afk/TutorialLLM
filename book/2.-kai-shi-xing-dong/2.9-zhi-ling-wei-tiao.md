# 2.9 指令微调

读者或许能够发现，训练数据的组织方式决定了模型的实际行为。之所以训练出的模型会一首接一首地写诗，是因为我们的训练数据就是这样设计的。在我们的数据集中，所有诗首尾相连串在一起，模型学习这些文本中的表述方式，自然也就学会了不停写诗。

对于实际的商用大模型来说，预训练的结果也是不停地输出文字。假如你提出一个问题，模型大概率不会回答你这个问题，而是尝试模仿你提问的方式无休止地提出其它问题。当然，你可能说，ChatGPT可不是这样。的确，那是因为ChatGPT并不属于预训练模型，而是经过了指令微调（Instruction Fine-tune）后的结果。

现在，我们有了一个只会文本补全的预训练模型，如何才能把它变成能回答问题乃至对话的聊天模型呢？

其实，问答或聊天本质上也是文本，只不过每段文本来自于不同的角色。对于ChatGPT来说，文本共有三种角色，分别是system、user和assistant。如果你用过OpenAI Chat API，你一定明白这三个角色各自的含义。简单来说，system是对整个会话的预设场景。比如，我们设置system文本为“你是一个优秀的心理咨询师”，模型后续的回复就会以心理咨询师的角色开展。user文本是用户给模型的实际输入，比如“我最近很郁闷，能告诉我该怎么办吗？”而assistant则是模型的输出，类似于“我理解你现在的感受，感觉郁闷时常常会让人有些迷茫。你能告诉我是什么让你感到郁闷吗？”

作为用户，我们已经习惯了在聊天窗口中与ChatGPT聊天。但实际上，网页背后的数据以system、user、assistant的格式存在。用户输入后，网站把system和user的文本输入模型，模型运行完毕后提取出assistant内容返回到用户界面。

同样地，要想获得这样的使用体验，就要用相同的数据格式训练模型。OpenAI的数据团队会收集大量对话数据，整理成system、user、assistant的格式，然后以同样的方式继续训练模型。此时的训练就叫做指令微调。对于刚刚举的例子，数据团队整理后的文本大概长这样：

> \[system]你是一个优秀的心理咨询师\[user]我最近很郁闷，能告诉我该怎么办吗？\[assistant]我理解你现在的感受，感觉郁闷常常会让人有些迷茫。你能告诉我是什么让你感到郁闷吗？

可以看到，文本中被插入了用方括号包裹的关键词。只要每条数据都用这几个关键词标注，模型在训练过程中就会慢慢明白这几个关键词的含义，从而将自己调整为一个对话模型。训练完毕后，只要输入包含system和user的前半部分，模型就可以输出assistant的后半部分，从而达到对话的效果。更重要的是，这类文本有明确结尾。无论system、user还是assistant，为了符合对话的主题，它们一定有各自的长度。模型可以从中学习到如何生成合适长度的回答，而不是无休止地扩展话题。

现在，回到我们的写诗场景。考虑可行性，我们选择一个容易学会的对话模式——根据题目写诗。这样的训练数据很多，我们可以把每首诗都整理成如下的格式：

> \<INS>請用以下題目寫一首詩\<INP>春夜喜雨\<RES>好雨知時節，當春乃發生。\n隨風潛入夜，潤物細無聲。\n野徑雲俱黑，江船火獨明。\n曉看紅濕處，花重錦官城

模型反复学习这种格式的文本，就会明白INS（instruction）、INP（input）、RES（response）分别代表指令、题目以及正文。当然，这里的关键字也是可以随便取的，只要训练和使用时保持一致即可。在我们的例子中，指令部分是固定的，我们只要求模型做这一项任务。如果是OpenAI等商用模型，他们会提供非常丰富的指令以训练模型能够从事各种任务。

指令微调的训练通常短于预训练。因为预训练阶段模型已经学会了如何说话，微调只是告诉他说话的格式，因而只需要训练一个增量，而不必从头开始。我们以[2.8节](2.8-yu-xun-lian.md)预训练后的模型为基础，按照刚刚介绍的数据格式进行微调，可以看到如下效果。

```
Epoch 0, step 0, train loss 0.0000, evaluate loss 8.5504
Generate a complete poem for title 春夜喜雨:
文請，曾說春來淚故花楊柳枝。

山中峰寺仙二首 二
高齋吟商賈居仙，欲嘯花開開却閉絲。
硯通四也應不見，却向宮江盡北山。
一字多堪杖不顧，紫芝多不見青山。
定開照鏡匳梅雨，上倚升階遶樹陰。
來此醉君

<Omit many iterations here...>

Epoch 4, step 800, train loss 3.2089, evaluate loss 3.3451
Generate a complete poem for title 春夜喜雨:
山村春色引，雨水曉光斜。
更問月中鏡，空啼千萬傳。
隱隱閑臥竹，神盤暗自風。
殘春望江島，不見磬聲王。
```

同样是每训练一段时间让模型试着输出一首诗。可以看到，在step为0时，模型还未开始微调，输出的文字虽然是诗句，但不是一首完整的诗。到第4轮的800步，输出变得很整洁。而且可以隐约感觉到，诗句的内容已经接近题目“春夜喜雨”的含义。模型像一个真正的对话AI一样，给出了有意义的答复。

至此，模型已经表现得有模有样，但别急，精彩的环节才刚刚开始。大模型在2023年爆发，最厉害的既不是预训练，也不是指令微调，而是下一节将要介绍的与人类偏好对齐。
